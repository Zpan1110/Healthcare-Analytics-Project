# Polycystic Ovary Syndrome (PCOS) Detection Using Machine Learning

## Introduction
Polycystic Ovary Syndrome (PCOS) is one of women's most prevalent endocrine disorders, affecting 5%~20% of the female population in productive age worldwide, causing approximately $3.7 billion in costs for only initial diagnosis and short-term reproductive endocrine morbidities in the US [1]. Due to hormonal imbalance and metabolic disorders, PCOS causes symptoms including irregular or missing menstrual periods, abnormal hair growth or loss, acne, low fertility, etc. Lack of proper treatment of PCOS may lead to further health concerns, including cardiovascular disease, diabetes, depression, and endometrial cancer [2]. There is no single test for diagnosing PCOS; thus, the guideline is not comprehensive, making the PCOS diagnosis still challenging [3, 4].

The academic community has recently started to explore the use of machine learning in PCOS diagnosis and detention. Machine learning has the potential to provide more accurate and timely diagnosis to patients, and its impacts have already been proven in heart disease prediction [5]. Besides, AI-based systems can better manage and track patient data, thus providing better and more instant care and helping doctors find unexplored correlations between some phenotypes and PCOS.

The purpose of this project is to use machine learning to make predictions on whether a patient has PCOS or not. We’ll also analyze the main indicators that are used in the model to provide insights on any underestimated correlations with PCOS. We’ve conducted techniques including exploratory data analysis, feature selection, model performance comparison with baseline, etc. We figured out 7 indicators that are highly predictive for PCOS and created a decision tree  model to help make predictions. We used cross-validation with 10 folders to ensure stochasticity in the train and test sets; our final F1-score of the train and test using this model is 0.892 and 0.815.

## Proposed Method
There are two questions we want to solve by conducting this project:
Can machine learning increase the rate of correct diagnosis for PCOS?
Are there any indicators that are important for the model to make predictions but still need to receive attention from academia?

To achieve this goal, we first conducted exploratory data analysis (EDA) to better understand the data. We filled in the missing values by using the mean of the corresponding variables because it will not cause our data to be skewed, and the majority of our data have values and are clean. We then calculated the correlation between all the variables to explore which might be the final features used by the model to make predictions. As an effective heuristic exploration, we decided to use the correlation matrix as a supportive material when selecting features but conducted feature selection by using forward selection to figure out how to wrap features together to make a better prediction model. Finally, we used the selected features to train the fine-tuned decision tree classification model, with an untrained default model as benchmark. While other fancy models might also be good choices and generate better outcomes, we want to emphasize the interpretability  and visualize the outcome in this research, which is why we chose the decision tree.

To clarify and simplify the questions, we have made the following assumptions and decisions:
1. We assume that all the labels (PCOS (Y/N)) in the dataset are correct. Even though overdiagnosis is common for PCOS, no research has been done to estimate the rate of wrong diagnoses.
2. We chose to use the F1-score to balance positives and negatives because we want both groups to have a good prediction for economic and clinical outcomes. We can’t find any research using the F1-score as the measurement so far, the highest accuracy is around 90%. Therefore, we assume as long as our models can reach an accuracy 85%, we’ll only compare the F1-scores to choose the final model.

## Data and Experiment Setup
### Data Description
The PCOS dataset contains 541 patient records with many physical and clinical parameters to help diagnose if a patient has PCOS or not. There are a total of 43 variables in this dataset, of which 41 are key attributes in determining if a patient does indeed have PCOS or not. Among the 41 independent attributes, 9 are categorical, and 32 are numerical. The PCOS dataset has been collected from Kaggle, which includes 541 records in total. There are 178 positive PCOS patients and 363 negative PCOS patients within this dataset. 

There were only few missing values and variable attribute errors, we impute them with corresponding column mean or mode before continuing our data exploration. Since the variable set is too large in terms of population samples, not all variables are equally important for diagnosing PCOS, so we decided to capture the variables that have high correlations (in this dataset, more than 20%) with the response variable PCOS (Y/N). We filtered down to 9 variables based on the correlation matrix which are: Weight (Kg), Cycle (R/I), Weight gain (Y/N), hair growth (Y/N), Skin darkening (Y/N), Pimples (Y/N), Fast food (Y/N), Follicle No. (L), Follicle No. (R). Exploratory Data Analysis is conducted on those numerical variables, using histograms and boxplots to identify their distributions and further eliminate extreme outliers.

### Feature Selection
In order to effectively allocate the most relevant variables that can predict PCOS, we further conducted feature selection. By using wrappers on forward selection, we observed that the model reached its local highest performance with average accuracy score of 0.881 of having 7 variables which are Follicle No. (R). Skin darkening (Y/N), Cycle (R/I),  Follicle No. (L), hair growth (Y/N), Hb (g/dl) and II beta-HCG (mIU/mL). These variables are used in further model setups. The model we chose has a greater than 0.85 accuracy, therefore we pass the assumption in Part 3 that this is an efficacious model. Below is the performance of stepwise feature selection, after 10 the model performance tends to get stable. 

When we designed our experimental evaluation plan, we wanted to optimize our model precision by achieving a high proportion of correct patient diagnosis. However, abusing the model precision would inflate the false positive rate. Hence, solely focusing on precision might ignore the equally significant component of recall, which calculates the proportion of actual positives our model correctly identifies.To strike a balance between precision and recall, we use the F1 score as our primary evaluation metric. The F1 score is the harmonic mean of precision and recall, giving us a single metric that considers both on the patients’ and hospitals’ side.

## Model Result
For the training and testing sets, the mean F-1 scores stand at 0.894 and 0.816, respectively. In comparison, the baseline decision model—without parameter tuning—yielded scores of 1.0 and 0.750. A T-test further underscores the grid search's efficacy, revealing a p-value of 0.047. This denotes a statistically significant improvement in performance due to the grid search.

In terms of mean Precision and Recall, they are respectively 0.861 and 0.778. These figures suggest that of the diagnosed PCOS patients, a substantial 86.1% are correctly identified. Furthermore, our model effectively diagnoses 77.8% of the genuine PCOS cases, streamlining their path to timely treatment. For the full visualization of the decision tree, we made it at the end of the jupyter notebook file, but we cannot download it due to system error of Graphvis.

## Discussion
In our research focused on PCOS diagnosis, our model demonstrated commendable performance in detecting PCOS. From the whole complex decision tree, we found some interesting insights and rule of thumbs about the quick prediction towards PCOS. Although the follicle numbers on the left side generally have a larger value than the right side, follicle numbers on the right side could be a very good starting point for the prediction. Given a greater than 7 follicle number on the right side, there is a high chance of PCOS if the patient has no weight gain in the recent period of time; while for a patient with weight gain and a stricter follicle condition (i.e. larger than 10), we can still get a medium high chance for PCOS detection. This simple heuristic methodology discovered by the model with only two variables could reduce the false positive classification to around 10%.

We noticed that the testing F1 score and Recall both have a relatively wide distribution and lower values. This might be because the metric recall emphasizes the exposure of the genuine PCOS cases while we only have an imbalanced dataset with 541 samples and about 30% of true PCOS in it. By accumulating more records for the whole 43 variable set and more balanced patient proportion, we do believe that a better and stabler outcome would be generated through the same model.

### Limitations
Our project may have the following limitations that might cause biased outcomes:
1. No data dictionary of the dataset: We found this dataset from Kaggle. Even though we found the original research that generated the dataset, the paper doesn’t provide many details on the variables’ descriptions. That might cause misunderstanding of the features.
2. Challenges of quantitative measurement in the dataset: Within the dataset, certain features—namely, Weight Gain, Fast Food, and Hair Growth—are qualitative in nature, meaning they are not based on specific numerical or standardized measurements. Instead, they are based on subjective descriptions or categorizations. This could lead to difficulty to interpret the model and utilize for future predictions.
3. No clues of how they sampled the dataset: The dataset itself might be biased due to its sampling methodology.
Scale of the research: Due to the dataset limitation, we might not be able to look at other features that play a role in the diagnosis process but unknown or unexplored, such as genetic factors, environment and lifestyles, etc.

However, we believe that there is a common concern about using machine learning in PCOS diagnosis: how to make sure the data label is right? The misdiagnosis of PCOS is pretty common, but there is no research that can estimate the rate of misdiagnosis. When using the label from traditional practice, we might face wrong labels in the datasets, and we’ll never know that they are wrong until our predictions go wrong and are proven in real medical cases. This should be a big concern for anyone who wants to use machine learning in predicting diseases that do not have clear diagnostic criteria.
